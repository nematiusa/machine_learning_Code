{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance metrics\n",
    "\n",
    "\n",
    "There are four other important metrics - AIC, AICc, BIC and Mallows Cp - that are commonly used for model evaluation and selection. These are an unbiased estimate of the model prediction error MSE. The lower these metrics, he better the model.\n",
    "\n",
    "\n",
    "\n",
    "**Generally, the most commonly used metrics, for measuring regression model quality and for comparing models, are: Adjusted R2, AIC, BIC and Cp.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIC stands for (Akaikeâ€™s Information Criteria),\n",
    "\n",
    "a metric developped by the Japanese Statistician, Hirotugu Akaike, 1970. The basic idea of AIC is to penalize the inclusion of additional variables to a model. It adds a penalty that increases the error when including additional terms. The lower the AIC, the better the model.\n",
    "AICc is a version of AIC corrected for small sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3\n",
      "MSE: 0.011\n",
      "AIC: -446.707\n"
     ]
    }
   ],
   "source": [
    "# calculate akaike information criterion for a linear regression model\n",
    "from math import log\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# calculate aic for regression\n",
    "def calculate_aic(n, mse, num_params):\n",
    "    aic = n * log(mse) + 2 * num_params\n",
    "    return aic\n",
    "\n",
    "# generate dataset\n",
    "X, y = make_regression(n_samples=100, n_features=2, noise=0.1)\n",
    "# define and fit the model on all data\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "# number of parameters\n",
    "num_params = len(model.coef_) + 1\n",
    "print('Number of parameters: %d' % (num_params))\n",
    "# predict the training set\n",
    "yhat = model.predict(X)\n",
    "# calculate the error\n",
    "mse = mean_squared_error(y, yhat)\n",
    "print('MSE: %.3f' % mse)\n",
    "# calculate the aic\n",
    "aic = calculate_aic(len(y), mse, num_params)\n",
    "print('AIC: %.3f' % aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIC (or Bayesian information criteria) \n",
    "is a variant of AIC with a stronger penalty for including additional variables to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGm33Ys8Doi3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3\n",
      "MSE: 0.011\n",
      "BIC: -438.606\n"
     ]
    }
   ],
   "source": [
    "# calculate bayesian information criterion for a linear regression model\n",
    "from math import log\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# calculate bic for regression\n",
    "def calculate_bic(n, mse, num_params):\n",
    "    bic = n * log(mse) + num_params * log(n)\n",
    "    return bic\n",
    "\n",
    "# generate dataset\n",
    "X, y = make_regression(n_samples=100, n_features=2, noise=0.1)\n",
    "# define and fit the model on all data\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "# number of parameters\n",
    "num_params = len(model.coef_) + 1\n",
    "print('Number of parameters: %d' % (num_params))\n",
    "# predict the training set\n",
    "yhat = model.predict(X)\n",
    "# calculate the error\n",
    "mse = mean_squared_error(y, yhat)\n",
    "print('MSE: %.3f' % mse)\n",
    "# calculate the bic\n",
    "bic = calculate_bic(len(y), mse, num_params)\n",
    "print('BIC: %.3f' % bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mallows Cp: \n",
    "A variant of AIC developed by Colin Mallows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "6- Regression Model Accuracy Metrics R-square, AIC, BIC, Cp and more.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
